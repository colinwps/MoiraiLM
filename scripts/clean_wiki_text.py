# path: scripts/clean_wiki_text.py
import os
import json
import logging
import argparse
from tqdm import tqdm

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')


def process_extracted_wiki(extracted_dir: str, output_file: str, min_line_length: int = 10):
    """
    è¯»å–WikiExtractorè¾“å‡ºçš„JSONæ–‡ä»¶ï¼Œæå–ã€æ¸…æ´—æ–‡æœ¬å¹¶ä¿å­˜åˆ°å•ä¸ªæ–‡ä»¶ä¸­ã€‚
    """
    if not os.path.isdir(extracted_dir):
        logging.error(f"è¾“å…¥çš„ç›®å½•ä¸å­˜åœ¨: {extracted_dir}")
        return

    total_articles = 0
    total_files = 0

    # ç¬¬ä¸€æ¬¡éå†ï¼šè·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    file_list = []
    for root, dirs, files in os.walk(extracted_dir):
        for file_name in files:
            # ä»…å¤„ç† WikiExtractor ç”Ÿæˆçš„ä»¥ 'wiki_' å¼€å¤´çš„æ–‡ä»¶
            if file_name.startswith('wiki_'):
                file_list.append(os.path.join(root, file_name))

    total_files = len(file_list)
    logging.info(f"æ‰¾åˆ° {total_files} ä¸ªæ–‡ä»¶ç­‰å¾…å¤„ç†ã€‚")
    if total_files == 0:
        logging.warning(f"ç›®å½• {extracted_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• 'wiki_' æ–‡ä»¶ã€‚è¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return

    # ç¬¬äºŒæ¬¡éå†ï¼šå¤„ç†æ–‡ä»¶å¹¶å†™å…¥è¾“å‡º
    with open(output_file, 'w', encoding='utf-8') as f_out:

        # ä½¿ç”¨ tqdm åŒ…è£…æ–‡ä»¶åˆ—è¡¨ï¼Œæ˜¾ç¤ºå¤„ç†è¿›åº¦
        for file_path in tqdm(file_list, desc="ğŸ“ æ­£åœ¨æå–ç»´åŸºæ–‡æœ¬"):

            with open(file_path, 'r', encoding='utf-8') as f_in:
                for line in f_in:
                    try:
                        article = json.loads(line)
                        text_content = article.get('text', '').strip()

                        # --- æ–‡æœ¬æ¸…æ´—å’Œè¿‡æ»¤ ---

                        # 1. è¿‡æ»¤æ‰è¿‡çŸ­çš„æ–‡ç« ï¼Œå®ƒä»¬é€šå¸¸æ˜¯å™ªéŸ³æˆ–é‡å®šå‘é¡µ
                        if len(text_content) < 200:
                            continue

                        # 2. ç§»é™¤æ–‡ç« æ ‡é¢˜ï¼ˆå¯é€‰ï¼Œé€šå¸¸åœ¨JSONè¾“å‡ºä¸­'text'å­—æ®µåŒ…å«æ ‡é¢˜ï¼‰
                        title = article.get('title', '')
                        if title and text_content.startswith(title):
                            text_content = text_content[len(title):].lstrip('\n')

                        # 3. æŒ‰è¡Œå¤„ç†æ–‡æœ¬ï¼Œè¿‡æ»¤çŸ­è¡Œå’Œé¢å¤–çš„ç©ºç™½
                        cleaned_lines = []
                        for text_line in text_content.split('\n'):
                            text_line = text_line.strip()
                            if len(text_line) >= min_line_length:
                                cleaned_lines.append(text_line)

                        final_text = ' '.join(cleaned_lines)

                        if final_text:
                            # å†™å…¥è¾“å‡ºæ–‡ä»¶ï¼Œç”¨ä¸¤ä¸ªæ¢è¡Œç¬¦åˆ†éš”æ–‡ç« 
                            f_out.write(final_text + '\n\n')
                            total_articles += 1

                    except json.JSONDecodeError:
                        logging.warning(f"æ— æ³•è§£æ JSON è¡Œï¼Œè·³è¿‡: {file_path}")
                    except Exception as e:
                        logging.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    logging.info(f"âœ… æ‰€æœ‰ç»´åŸºç™¾ç§‘æ–‡æœ¬å·²æˆåŠŸæå–ã€‚æ€»æ–‡ç« æ•°: {total_articles}ã€‚æ–‡ä»¶å·²ä¿å­˜åˆ° {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description="ä» WikiExtractor è¾“å‡ºçš„ JSON æ–‡ä»¶ä¸­æå–å¹¶æ¸…æ´—çº¯æ–‡æœ¬ã€‚",
        formatter_class=argparse.RawTextHelpFormatter
    )

    # ä½ç½®å‚æ•° 1: è¾“å…¥ç›®å½•
    parser.add_argument(
        "extracted_directory",
        type=str,
        help="WikiExtractor è¾“å‡ºçš„ç›®å½•è·¯å¾„ (e.g., extracted_wiki_zh)"
    )

    # ä½ç½®å‚æ•° 2: è¾“å‡ºæ–‡ä»¶
    parser.add_argument(
        "output_filename",
        type=str,
        help="æœ€ç»ˆåˆå¹¶çš„çº¯æ–‡æœ¬æ–‡ä»¶è·¯å¾„ (e.g., cleaned_wiki.txt)"
    )

    # å¯é€‰å‚æ•°: æœ€å°è¡Œé•¿
    parser.add_argument(
        "--min_line_length",
        type=int,
        default=10,
        help="æ–‡ç« ä¸­å•è¡Œæ–‡æœ¬å¿…é¡»è¾¾åˆ°çš„æœ€å°é•¿åº¦ï¼Œç”¨äºè¿‡æ»¤å™ªéŸ³ã€‚é»˜è®¤å€¼: 10"
    )

    args = parser.parse_args()

    process_extracted_wiki(
        args.extracted_directory,
        args.output_filename,
        args.min_line_length
    )


if __name__ == "__main__":
    main()